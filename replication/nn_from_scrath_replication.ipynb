{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a581b26f-98a1-4b38-87c6-82c6329ba6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa7a7b5-0e0b-4ce1-9399-e171811f6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.64.0)\n",
      "Requirement already satisfied: python-slugify in /usr/lib/python3/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.10)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from kaggle) (5.0.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kaggle) (2.8)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110685 sha256=80e8344ee439733c056110b45a27c043f8a582d90fc33bea6c1fed8dbd47ff54\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/ed/a5/da3a0cfb13373d1ace41cafa4f2467d858c55c52473ba72799\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.16\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3103440-8320-44a7-a1e5-cea7f115f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp ../kaggle.json /root/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e619c5-7a16-49cf-9979-203277bf8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying over from JH notebook\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: path = Path('../input/titanic')\n",
    "else:\n",
    "    path = Path('titanic')\n",
    "    if not path.exists():\n",
    "        import zipfile,kaggle\n",
    "        kaggle.api.competition_download_cli(str(path))\n",
    "        zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f50c9-822f-4c76-807a-d383a0501bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a5c272-69bf-4407-aae0-4c8e3bd0359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "orig_train_df = pd.read_csv(path/'train.csv')\n",
    "train_df = copy.deepcopy(orig_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240dcde-874d-4871-bef6-b44bfd9406a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd20e31-3529-454a-99c6-3af803645525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf48c38b-9306-48e2-8a14-7aa74f31c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check which ones JH included\n",
    "cat_vars = ['Pclass', 'Sex', 'Embarked']\n",
    "num_vars = ['Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094d424-e78c-4ca8-a2e7-bb93f7669c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af697e28-42bd-4fce-991f-395bab7ee66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.505672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp     Parch      Fare\n",
       "0    0.2750  0.125  0.000000  0.317521\n",
       "1    0.4750  0.125  0.000000  0.683873\n",
       "2    0.3250  0.000  0.000000  0.331789\n",
       "3    0.4375  0.125  0.000000  0.636672\n",
       "4    0.4375  0.000  0.000000  0.334298\n",
       "..      ...    ...       ...       ...\n",
       "886  0.3375  0.000  0.000000  0.411118\n",
       "887  0.2375  0.000  0.000000  0.545154\n",
       "888  0.3000  0.125  0.333333  0.505672\n",
       "889  0.3250  0.000  0.000000  0.545154\n",
       "890  0.4000  0.000  0.000000  0.328210\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = train_df[num_vars].fillna(train_df[num_vars].mode().iloc[0])\n",
    "num_df['Fare'] = np.log(num_df['Fare'] + 1e-10)\n",
    "\n",
    "# Going through an easier approach rather than typical norm\n",
    "num_df = num_df / num_df.max()\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c4477b-7ebb-4cae-b3b3-54fc026d5614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[cat_vars].describe(include='all')\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d47018-c7f7-4c4e-b4ae-392b9d9fe6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Pclass.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82d5e03-5922-45e7-9a31-99066620b7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0           0         0         1           0         1           0           0           1\n",
       "1           1         0         0           1         0           1           0           0\n",
       "2           0         0         1           1         0           0           0           1\n",
       "3           1         0         0           1         0           0           0           1\n",
       "4           0         0         1           0         1           0           0           1\n",
       "..        ...       ...       ...         ...       ...         ...         ...         ...\n",
       "886         0         1         0           0         1           0           0           1\n",
       "887         1         0         0           1         0           0           0           1\n",
       "888         0         0         1           1         0           0           0           1\n",
       "889         1         0         0           0         1           1           0           0\n",
       "890         0         0         1           0         1           0           1           0\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Curious how in-depth you should conside N/As\n",
    "cat_df = pd.get_dummies(train_df[cat_vars], columns=cat_vars)\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975b9350-d7ad-4c3b-a789-918ab7632019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might need to normalize after creating the dummy vars?\n",
    "proc_train_df = num_df.join(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f50448-d7a7-4668-820e-6486315c9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realize, going back to this, that we're not saving the mode but taking it for each piece of data we bring in\n",
    "def process_df(path, has_dependent=True):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.fillna(df.mode().iloc[0])\n",
    "    \n",
    "    \n",
    "    # TODO: Check which ones JH included\n",
    "    cat_vars = ['Pclass', 'Sex', 'Embarked']\n",
    "    num_vars = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "    \n",
    "    \n",
    "    num_df = df[num_vars]\n",
    "    num_df['Fare'] = np.log(num_df['Fare'] + 1e-10)\n",
    "    # Going for an easier approach rather than typical norm\n",
    "    num_df = num_df / num_df.max()\n",
    "\n",
    "    cat_df = pd.get_dummies(df[cat_vars], columns=cat_vars)\n",
    "    cat_df['const'] = 1\n",
    "    \n",
    "    if has_dependent:\n",
    "        return (num_df.join(cat_df), df['Survived'])\n",
    "    else:\n",
    "        return num_df.join(cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b0a586-6c93-4b1e-946e-6967bd91b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/3771005558.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  num_df['Fare'] = np.log(num_df['Fare'] + 1e-10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.505672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp     Parch      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  const\n",
       "0    0.2750  0.125  0.000000  0.317521         0         0         1           0         1           0           0           1      1\n",
       "1    0.4750  0.125  0.000000  0.683873         1         0         0           1         0           1           0           0      1\n",
       "2    0.3250  0.000  0.000000  0.331789         0         0         1           1         0           0           0           1      1\n",
       "3    0.4375  0.125  0.000000  0.636672         1         0         0           1         0           0           0           1      1\n",
       "4    0.4375  0.000  0.000000  0.334298         0         0         1           0         1           0           0           1      1\n",
       "..      ...    ...       ...       ...       ...       ...       ...         ...       ...         ...         ...         ...    ...\n",
       "886  0.3375  0.000  0.000000  0.411118         0         1         0           0         1           0           0           1      1\n",
       "887  0.2375  0.000  0.000000  0.545154         1         0         0           1         0           0           0           1      1\n",
       "888  0.3000  0.125  0.333333  0.505672         0         0         1           1         0           0           0           1      1\n",
       "889  0.3250  0.000  0.000000  0.545154         1         0         0           0         1           1           0           0      1\n",
       "890  0.4000  0.000  0.000000  0.328210         0         0         1           0         1           0           1           0      1\n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, train_dep = process_df(path/'train.csv')\n",
    "t_dep = torch.tensor(train_dep)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b522160b-d6fb-4e21-b9ff-6efd58e6937a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Pclass_1      0\n",
       "Pclass_2      0\n",
       "Pclass_3      0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "const         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79e887b-cb8a-42d7-8735-055908eee148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/3771005558.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  num_df['Fare'] = np.log(num_df['Fare'] + 1e-10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.402083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.498031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  SibSp     Parch      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  const\n",
       "0    0.453947  0.000  0.000000  0.329840         0         0         1           0         1           0           1           0      1\n",
       "1    0.618421  0.125  0.000000  0.311896         0         0         1           1         0           0           0           1      1\n",
       "2    0.815789  0.000  0.000000  0.363976         0         1         0           0         1           0           1           0      1\n",
       "3    0.355263  0.000  0.000000  0.346051         0         0         1           0         1           0           0           1      1\n",
       "4    0.289474  0.125  0.111111  0.402083         0         0         1           1         0           0           0           1      1\n",
       "..        ...    ...       ...       ...       ...       ...       ...         ...       ...         ...         ...         ...    ...\n",
       "413  0.276316  0.000  0.000000  0.334298         0         0         1           0         1           0           0           1      1\n",
       "414  0.513158  0.000  0.000000  0.751796         1         0         0           1         0           1           0           0      1\n",
       "415  0.506579  0.000  0.000000  0.317521         0         0         1           0         1           0           0           1      1\n",
       "416  0.276316  0.000  0.000000  0.334298         0         0         1           0         1           0           0           1      1\n",
       "417  0.276316  0.125  0.111111  0.498031         0         0         1           0         1           1           0           0      1\n",
       "\n",
       "[418 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = process_df(path/'test.csv', has_dependent=False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "978552cb-42cc-490c-9a38-dcf628c74bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4539, 0.0000, 0.0000, 0.3298, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.6184, 0.1250, 0.0000, 0.3119, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.8158, 0.0000, 0.0000, 0.3640, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.3553, 0.0000, 0.0000, 0.3461, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.2895, 0.1250, 0.1111, 0.4021, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.1842, 0.0000, 0.0000, 0.3561, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.3947, 0.0000, 0.0000, 0.3257, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.4868, 0.1250, 0.0000, 0.7212, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.3684, 0.0000, 0.0000, 0.3287, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.2763, 0.0000, 0.0000, 0.3343, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.5132, 0.0000, 0.0000, 0.7518, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.5066, 0.0000, 0.0000, 0.3175, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.2763, 0.0000, 0.0000, 0.3343, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.2763, 0.1250, 0.1111, 0.4980, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_indep = torch.tensor(test_df.values)\n",
    "tst_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d076c8de-dabf-4c19-9c6b-110158a60733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Pclass_1      0\n",
       "Pclass_2      0\n",
       "Pclass_3      0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "const         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c310174-b1b9-4d62-9320-703e84dd3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great success! We can move into building out model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b01fdc6-9563-401c-affc-82e04505ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3081d83a-f368-4271-821d-3167ad392aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0283,  0.4963,  0.4554, -0.4240, -0.1928,  0.0285, -0.1892, -0.2169, -0.4901,  0.0793, -0.1776,  0.1938,  0.4816])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.rand(train_df.shape[1]) - 0.5\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c6d2c-6bc8-46c1-9233-32d0bf30d97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "047e61bf-dd0b-4182-9dc9-7be5583cfac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 0.1250, 0.0000, 0.3175, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4750, 0.1250, 0.0000, 0.6839, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.3318, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4375, 0.1250, 0.0000, 0.6367, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4375, 0.0000, 0.0000, 0.3343, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.3000, 0.0000, 0.0000, 0.3422, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.6750, 0.0000, 0.0000, 0.6329, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.3125, 0.0000, 0.0000, 0.3130, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4875, 0.0000, 0.8333, 0.5404, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.3375, 0.0000, 0.0000, 0.4111, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.2375, 0.0000, 0.0000, 0.5452, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.3000, 0.1250, 0.3333, 0.5057, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.5452, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4000, 0.0000, 0.0000, 0.3282, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_df = torch.tensor(train_df.values)\n",
    "tensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb5b9e2d-eb27-476f-b349-8c5660f88269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0078,  0.0620,  0.0000, -0.1346, -0.0000,  0.0000, -0.1892, -0.0000, -0.4901,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0134,  0.0620,  0.0000, -0.2900, -0.1928,  0.0000, -0.0000, -0.2169, -0.0000,  0.0793, -0.0000,  0.0000,  0.4816],\n",
       "        [-0.0092,  0.0000,  0.0000, -0.1407, -0.0000,  0.0000, -0.1892, -0.2169, -0.0000,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0124,  0.0620,  0.0000, -0.2700, -0.1928,  0.0000, -0.0000, -0.2169, -0.0000,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0124,  0.0000,  0.0000, -0.1418, -0.0000,  0.0000, -0.1892, -0.0000, -0.4901,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0085,  0.0000,  0.0000, -0.1451, -0.0000,  0.0000, -0.1892, -0.0000, -0.4901,  0.0000, -0.1776,  0.0000,  0.4816],\n",
       "        [-0.0191,  0.0000,  0.0000, -0.2684, -0.1928,  0.0000, -0.0000, -0.0000, -0.4901,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        ...,\n",
       "        [-0.0088,  0.0000,  0.0000, -0.1327, -0.0000,  0.0000, -0.1892, -0.0000, -0.4901,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0138,  0.0000,  0.3795, -0.2292, -0.0000,  0.0000, -0.1892, -0.2169, -0.0000,  0.0000, -0.1776,  0.0000,  0.4816],\n",
       "        [-0.0095,  0.0000,  0.0000, -0.1743, -0.0000,  0.0285, -0.0000, -0.0000, -0.4901,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0067,  0.0000,  0.0000, -0.2312, -0.1928,  0.0000, -0.0000, -0.2169, -0.0000,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0085,  0.0620,  0.1518, -0.2144, -0.0000,  0.0000, -0.1892, -0.2169, -0.0000,  0.0000, -0.0000,  0.1938,  0.4816],\n",
       "        [-0.0092,  0.0000,  0.0000, -0.2312, -0.1928,  0.0000, -0.0000, -0.0000, -0.4901,  0.0793, -0.0000,  0.0000,  0.4816],\n",
       "        [-0.0113,  0.0000,  0.0000, -0.1392, -0.0000,  0.0000, -0.1892, -0.0000, -0.4901,  0.0000, -0.1776,  0.0000,  0.4816]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (tensor_df * weights)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2a9c6c1-fca1-4636-a8af-a5442baeb3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 13])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "392a4fb7-cf48-4c56-bbe8-e82619e4cc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62ca0948-5a48-45b3-bfe9-0722737150c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + 1 / torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10d2c692-920a-44cc-bbc7-b6d5af296bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_implementation_sigmoid = torch.sigmoid(result.sum(axis=1))\n",
    "my_implementation_sigmoid = sigmoid(result.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2083418-9b53-4c67-96ed-5e24e80933dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(891)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Awesome!\n",
    "(torch_implementation_sigmoid == torch_implementation_sigmoid).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddfdbe00-eedb-4a71-90e7-71efa8b77194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0283,  0.4963,  0.4554, -0.4240, -0.1928,  0.0285, -0.1892, -0.2169, -0.4901,  0.0793, -0.1776,  0.1938,  0.4816])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ed6204a-a854-4bb4-b0e7-21da6f6cfa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.3298, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2631, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2053, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2049, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2095, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2113, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2120, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2123, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2125, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2126, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2126, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2125, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2124, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2122, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2117, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2104, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.2066, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1975, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1900, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1889, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1893, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1901, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1910, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1913, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1906, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1895, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1884, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1884, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1884, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1884, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(0.1885, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(nan, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement actual training\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def mae(preds, actual):\n",
    "    return torch.abs(preds - actual).mean()\n",
    "\n",
    "actual = torch.tensor(orig_train_df['Survived'])\n",
    "weights = torch.rand(train_df.shape[1]) - 0.5\n",
    "weights.requires_grad_()\n",
    "\n",
    "def training_step(step, lr):\n",
    "    global weights\n",
    "    \n",
    "    layer_results = tensor_df * weights\n",
    "    preds = sigmoid(layer_results.sum(axis=1))\n",
    "    loss = mae(preds, actual)\n",
    "\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(\"loss:\", loss)\n",
    "\n",
    "    # print(weights.data)\n",
    "        \n",
    "    # if torch.isnan(loss):\n",
    "    #     print(weights)\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights -= lr * weights.grad\n",
    "        \n",
    "def train(steps=10000, lr=3e-3):\n",
    "    for i in range(steps):\n",
    "        training_step(i, lr)\n",
    "        \n",
    "def pred(input_tensor):\n",
    "    layer_results = input_tensor * weights\n",
    "    return sigmoid(layer_results.sum(axis=1))\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48118328-f278-427f-853e-5ef2eb8c5ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e65ee1ee-959a-482e-9772-d57fa5e281f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights - weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dddc7c4-0a8e-4009-92c0-c0fc52214b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.331789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.505672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp     Parch      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  const\n",
       "0    0.2750  0.125  0.000000  0.317521         0         0         1           0         1           0           0           1      1\n",
       "1    0.4750  0.125  0.000000  0.683873         1         0         0           1         0           1           0           0      1\n",
       "2    0.3250  0.000  0.000000  0.331789         0         0         1           1         0           0           0           1      1\n",
       "3    0.4375  0.125  0.000000  0.636672         1         0         0           1         0           0           0           1      1\n",
       "4    0.4375  0.000  0.000000  0.334298         0         0         1           0         1           0           0           1      1\n",
       "..      ...    ...       ...       ...       ...       ...       ...         ...       ...         ...         ...         ...    ...\n",
       "886  0.3375  0.000  0.000000  0.411118         0         1         0           0         1           0           0           1      1\n",
       "887  0.2375  0.000  0.000000  0.545154         1         0         0           1         0           0           0           1      1\n",
       "888  0.3000  0.125  0.333333  0.505672         0         0         1           1         0           0           0           1      1\n",
       "889  0.3250  0.000  0.000000  0.545154         1         0         0           0         1           1           0           0      1\n",
       "890  0.4000  0.000  0.000000  0.328210         0         0         1           0         1           0           1           0      1\n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since weights are blowing up, going back through and checking my notebook against JH\n",
    "# TODO: Plug in fastbook to write these up; learn in public bb\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd455e-5305-4567-acb9-e0b1e3604d9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploring NaN weights\n",
    "\n",
    "- Like the options to change display:\n",
    "\n",
    "```python\n",
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)\n",
    "```\n",
    "\n",
    "- Doesn't look like he \"normalized\" numerical values\n",
    "- cat_vars = [sex, pclass, embarked] which lines up with mine!\n",
    "- num_vars line up as well, Age, SibSp, Parch, and Fare.\n",
    "- Primary difference looks like he didn't\n",
    "- Also his naming scheme looks a lot cleaner than mine; something to learn here\n",
    "- I added a const column, might be better, but JH might've been just going the easy way\n",
    "\n",
    "- Ahhhhh looks like problem might be `coeffs.grad.zero_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa8508f8-55b1-45e4-9710-06aff24e3f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0911, -0.0258,  0.0000,  0.0628,  0.0000, -0.0000, -0.2177,  0.0000,  0.4152, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.1573, -0.0258,  0.0000,  0.1352,  0.3000, -0.0000, -0.0000,  0.1816,  0.0000, -0.1029,  0.0000, -0.0000,  0.0529],\n",
       "        [-0.1076, -0.0000,  0.0000,  0.0656,  0.0000, -0.0000, -0.2177,  0.1816,  0.0000, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.1449, -0.0258,  0.0000,  0.1258,  0.3000, -0.0000, -0.0000,  0.1816,  0.0000, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.1449, -0.0000,  0.0000,  0.0661,  0.0000, -0.0000, -0.2177,  0.0000,  0.4152, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.0993, -0.0000,  0.0000,  0.0676,  0.0000, -0.0000, -0.2177,  0.0000,  0.4152, -0.0000,  0.3742, -0.0000,  0.0529],\n",
       "        [-0.2235, -0.0000,  0.0000,  0.1251,  0.3000, -0.0000, -0.0000,  0.0000,  0.4152, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        ...,\n",
       "        [-0.1035, -0.0000,  0.0000,  0.0619,  0.0000, -0.0000, -0.2177,  0.0000,  0.4152, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.1614, -0.0000,  0.0154,  0.1068,  0.0000, -0.0000, -0.2177,  0.1816,  0.0000, -0.0000,  0.3742, -0.0000,  0.0529],\n",
       "        [-0.1118, -0.0000,  0.0000,  0.0813,  0.0000, -0.3390, -0.0000,  0.0000,  0.4152, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.0786, -0.0000,  0.0000,  0.1078,  0.3000, -0.0000, -0.0000,  0.1816,  0.0000, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.0993, -0.0258,  0.0062,  0.1000,  0.0000, -0.0000, -0.2177,  0.1816,  0.0000, -0.0000,  0.0000, -0.0806,  0.0529],\n",
       "        [-0.1076, -0.0000,  0.0000,  0.1078,  0.3000, -0.0000, -0.0000,  0.0000,  0.4152, -0.1029,  0.0000, -0.0000,  0.0529],\n",
       "        [-0.1325, -0.0000,  0.0000,  0.0649,  0.0000, -0.0000, -0.2177,  0.0000,  0.4152, -0.0000,  0.3742, -0.0000,  0.0529]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.rand(train_df.shape[1]) - 0.5\n",
    "tensor_df * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad30d6-538d-497b-b535-5d63d42ba1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84085fd6-760b-433c-b649-c51fa02e6b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([891, 13]), torch.Size([13]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_df.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dc31385-aecd-44b4-8aa2-6623c39edf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 0.1250, 0.0000, 0.3175, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4750, 0.1250, 0.0000, 0.6839, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.3318, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4375, 0.1250, 0.0000, 0.6367, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4375, 0.0000, 0.0000, 0.3343, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.3000, 0.0000, 0.0000, 0.3422, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.6750, 0.0000, 0.0000, 0.6329, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.3125, 0.0000, 0.0000, 0.3130, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.4875, 0.0000, 0.8333, 0.5404, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.3375, 0.0000, 0.0000, 0.4111, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.2375, 0.0000, 0.0000, 0.5452, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.3000, 0.1250, 0.3333, 0.5057, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000],\n",
       "        [0.3250, 0.0000, 0.0000, 0.5452, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n",
       "        [0.4000, 0.0000, 0.0000, 0.3282, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b497dd0-94b6-4d18-8587-196110d49910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91112a35-44f5-4d3f-9d4a-1955d920fbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2886ddd6-f0f7-4d14-8fef-60c9a6675eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch lesson_5_from_scratch\n",
      "Your branch is up to date with 'origin/lesson_5_from_scratch'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   nn_from_scrath_replication.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mtitanic/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"treyroyalt@gmail.com\"\n",
    "!git config --global user.name \"jpr2000\"\n",
    "!git commit -m \"Fix training with validation stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54c8c2ea-3e71-4048-9ec5-f267f7fe3b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1157,  0.3838, -0.1058,  0.4091,  0.0910,  0.5928,  0.5891,  0.1839, -0.0930, -0.1832], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (tensor_df*weights).sum(axis=1)\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0be44913-73bb-4988-bb7d-20fec717d143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4450, dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(t_dep - preds).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4eb0cd5-3908-40c5-b426-603d02da5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(inputs, weights): return sigmoid((inputs*weights).sum(axis=1))\n",
    "def calc_loss(inputs, weights, actual): \n",
    "    return torch.abs(actual - calc_preds(inputs, weights)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96a7f9c9-96cd-4e85-8006-ca92900da9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4949, dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_loss(tensor_df, weights, t_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc54bc97-2751-44e4-80c5-55c380d2c075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3311, -0.2061,  0.0185,  0.1977,  0.3000, -0.3390, -0.2177,  0.1816,  0.4152, -0.1029,  0.3742, -0.0806,  0.0529])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2694e671-c0cb-46dc-a02a-43e5c3eac918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.4949, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.3642, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.3171, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2867, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2683, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2567, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2488, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2431, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2388, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2354, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2327, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2304, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2286, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2269, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2255, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2243, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2232, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2222, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2213, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2205, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2197, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2190, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2183, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2176, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2170, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2164, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2159, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2153, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2148, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2143, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2138, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2133, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2128, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2124, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2119, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2115, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2110, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2106, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2102, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2099, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2095, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2091, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2088, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2084, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2081, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2077, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2074, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2071, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2068, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2065, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2063, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2060, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2057, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2055, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2052, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2050, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2047, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2045, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2043, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2041, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2038, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2036, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2034, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2032, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2031, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2029, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2027, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2025, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2023, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2022, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2020, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2019, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2017, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2014, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2013, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2011, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2010, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2008, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2007, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2006, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2005, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2003, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2002, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2001, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.2000, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1999, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1998, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1996, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1995, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1994, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1993, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1992, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1991, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1990, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1989, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1989, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1988, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1987, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1986, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n"
     ]
    }
   ],
   "source": [
    "# Going to see where we went wrong\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "weights = torch.rand(train_df.shape[1]) - 0.5\n",
    "weights.requires_grad_()\n",
    "\n",
    "def training_step(step, lr):\n",
    "    global weights\n",
    "    \n",
    "    # layer_results = tensor_df * weights\n",
    "    # preds = sigmoid(layer_results.sum(axis=1))\n",
    "    # loss = mae(preds, actual)\n",
    "    \n",
    "    loss = calc_loss(tensor_df, weights, t_dep)\n",
    "\n",
    "    # print(weights.data)\n",
    "        \n",
    "    # if torch.isnan(loss):\n",
    "    #     print(weights)\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights.sub_(weights.grad * lr)\n",
    "        \n",
    "        # Think the following line is where we went wrong\n",
    "        weights.grad.zero_()\n",
    "        if step % 100 == 0:\n",
    "            print(\"loss:\", loss)\n",
    "            print(\"val loss:\", )\n",
    "        \n",
    "        \n",
    "def train(steps=10000, lr=0.1):\n",
    "    global weights\n",
    "    weights = torch.rand(train_df.shape[1]) - 0.5\n",
    "    weights.requires_grad_()\n",
    "    \n",
    "    for i in range(steps):\n",
    "        training_step(i, lr)\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d429c8-5298-4a4f-88af-f7c43efc08b5",
   "metadata": {},
   "source": [
    "Results now look similar to Jeremy's! Importance of zeroing out your gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b022d85-a3a9-4dec-bee6-985304ca7223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a8d94a7-ab08-4316-9c3e-ac829b81ee08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2976,  1.1950,  1.0525, -0.3461, -1.6866, -1.7561,  3.2334, -4.5529,  5.1971, -0.7122, -1.3137,  2.2640,  0.1003],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5de38618-3b87-4b49-a807-1a2ed0ecbab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.4976, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1892, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1889, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1888, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1888, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1887, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1885, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1885, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1882, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1878, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1874, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1871, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1868, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1866, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1864, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1862, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1861, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1859, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1850, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1848, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1847, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1846, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1845, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1843, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1842, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1841, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1840, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1839, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1839, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1838, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1837, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1836, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1836, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1835, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1834, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1823, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1761, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1752, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1749, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1746, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1744, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1742, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1741, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1739, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1738, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1737, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1735, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1734, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1733, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1732, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1732, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1731, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1730, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1729, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1728, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1728, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1727, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1726, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1726, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1725, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1725, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1724, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1724, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1723, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1723, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1722, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1722, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1721, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1721, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1721, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1720, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1720, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1720, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1719, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1719, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1719, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n",
      "loss: tensor(0.1718, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "val loss:\n"
     ]
    }
   ],
   "source": [
    "train(lr=1e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5f858-1ad5-4a02-949e-840e86db05ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's actually build out a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cda7fa3f-7e94-4327-ba25-d386663731ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "\n",
    "train_idx, val_idx = RandomSplitter(seed=42)(train_df)\n",
    "\n",
    "trn_indep, val_indep = tensor_df[train_idx], tensor_df[val_idx]\n",
    "trn_dep, val_dep     = t_dep[train_idx], t_dep[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13a5eeae-b1a9-4129-a204-d211e2b7931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying we still have all our data \n",
    "assert trn_indep.shape[0] + val_indep.shape[0] == 891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14c4d1b8-f69e-44ca-bbcd-8195969adace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_84/3909039809.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??calc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78d58167-37d6-4e0a-879e-13894021dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating for accuracy\n",
    "# TODO: Need a better naming scheme\n",
    "\n",
    "# TODO: Update this with new variables\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "weights\n",
    "\n",
    "def training_step(step, lr):\n",
    "    global weights\n",
    "    \n",
    "    loss = calc_loss(trn_indep, weights, trn_dep)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights.sub_(weights.grad * lr)\n",
    "        weights.grad.zero_()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            trn_loss = calc_loss(trn_indep, weights, trn_dep).item()\n",
    "            val_loss = calc_loss(val_indep, weights, val_dep).item()\n",
    "            print(trn_loss, val_loss)\n",
    "        \n",
    "        \n",
    "def train(steps=10000, lr=0.1):\n",
    "    torch.manual_seed(0)\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    global weights\n",
    "    weights = torch.rand(train_df.shape[1]) - 0.5\n",
    "    weights.requires_grad_()\n",
    "    \n",
    "    for i in range(steps):\n",
    "        training_step(i, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9194e5f0-4364-4744-a676-0dcc844d3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5303622207049395 0.5319113867953892\n",
      "0.20148153446224695 0.18740216158440876\n",
      "0.19735286147191075 0.18160683233195013\n",
      "0.19579616599382862 0.17934296847835493\n",
      "0.1949595229515259 0.17811480634403976\n",
      "0.19443323892736752 0.1773427211462587\n",
      "0.19407070990278433 0.1768129781311443\n",
      "0.19380553766900835 0.17642739246372777\n",
      "0.1936030634730265 0.17613443709475138\n",
      "0.19344336782294858 0.17590446493743944\n"
     ]
    }
   ],
   "source": [
    "train(lr=1e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f33fb048-adbb-450e-a65d-45aa2d05823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_84/3909039809.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??calc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9a3e7d8-c5bf-4a6b-ba8d-879bbe6a1418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying we still have all our data \n",
    "trn_indep.shape[0] + val_indep.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c340d99-3acf-4eb0-845c-0740522571fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_84/3909039809.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??calc_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5cbc4d5b-f771-4f14-a08a-7479c8822f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([418, 13])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_indep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "616bedc0-13b7-4233-b567-b0119c11e5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0000,     0.0245,     0.0202,     0.0000,     0.0449,     0.0000,     0.9900,     0.0000,     0.9790,     0.0000,     0.0000,\n",
       "            0.0000,     0.9978,     0.0000,     0.9955,     1.0000,     0.0446,     0.0000,     0.0438,     0.9545,     0.0049,     0.0000,\n",
       "            0.9985,     0.0169,     1.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0293,\n",
       "            0.0417,     0.0103,     0.0000,     0.0748,     0.0752,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9984,\n",
       "            0.9957,     0.0000,     0.0092,     0.0000,     1.0000,     0.0385,     0.0000,     0.0196,     0.9971,     0.9931,     0.0234,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.9921,     0.0095,     0.9988,\n",
       "            0.9930,     0.0000,     0.0139,     0.9890,     0.9916,     0.0000,     0.0599,     0.0149,     1.0000,     0.0154,     0.0000,\n",
       "            0.9910,     0.0000,     0.9916,     0.0000,     0.0000,     0.0000,     0.0000,     0.0654,     0.0000,     0.9908,     0.0812,\n",
       "            0.9923,     0.0000,     0.0525,     0.0000,     0.9965,     0.0000,     0.0164,     0.0000,     0.9896,     0.0000,     0.0768,\n",
       "            0.0000,     1.0000,     0.0000,     0.0000,     0.0000,     0.9667,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0130,     0.9923,     1.0000,     0.9928,     0.9934,     0.0000,     0.0000,     0.0823,     0.0129,     0.9979,     0.9991,\n",
       "            0.0000,     1.0000,     0.0000,     0.0000,     0.0759,     0.0000,     0.9847,     0.0000,     0.0000,     0.0000,     0.0073,\n",
       "            0.0452,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0708,     0.0000,     0.0132,     0.9981,     0.0029,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000,     0.0000,     0.0000,     0.0377,\n",
       "            0.0000,     0.0000,     0.9984,     0.0707,     0.0000,     0.0505,     0.9923,     0.0000,     0.9986,     0.0000,     0.0000,\n",
       "            0.0418,     0.0088,     0.0000,     1.0000,     0.0734,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9987,\n",
       "            0.9989,     0.0050,     0.9972,     1.0000,     0.0000,     0.0074,     0.9981,     0.0000,     1.0000,     0.0000,     0.9986,\n",
       "            0.0000,     0.0031,     0.0000,     0.0000,     0.0000,     0.0000,     0.0211,     0.0001,     0.0000,     0.0238,     0.0810,\n",
       "            0.0000,     0.0749,     0.9927,     0.0000,     0.0069,     0.9987,     0.0000,     0.0184,     0.9884,     0.0000,     1.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0001,     0.9946,     0.0074,     0.0000,     0.9923,     0.0000,     1.0000,     0.0000,\n",
       "            1.0000,     0.0000,     0.9987,     0.0000,     1.0000,     0.9707,     0.0000,     0.9923,     0.0000,     0.0000,     0.0001,\n",
       "            0.9985,     0.0000,     0.0000,     0.0080,     0.0000,     0.0038,     0.0000,     0.9981,     1.0000,     1.0000,     0.9968,\n",
       "            0.0060,     0.0000,     0.0000,     0.0000,     0.9988,     0.0000,     0.9979,     0.9682,     0.9987,     0.0000,     0.0120,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9989,     0.0000,     0.0000,     0.0000,     0.9980,     0.0805,\n",
       "            0.0177,     0.0000,     0.0000,     0.0000,     0.0748,     0.0000,     0.0096,     0.0000,     1.0000,     0.9893,     0.0000,\n",
       "            0.9984,     0.0000,     0.0000,     0.0000,     0.0000,     0.0712,     0.0000,     0.9923,     0.9739,     0.0812,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9899,     0.0000,     0.0000,     0.0000,     0.0000,     1.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0233,     0.0000,     0.0000,     0.9923,     0.9907,     0.0000,     0.0000,\n",
       "            0.0000,     0.0273,     0.0000,     0.0000,     0.0000,     0.9877,     1.0000,     0.9932,     0.0050,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9978,     0.0000,     0.9978,     0.0097,     0.0000,     0.0000,\n",
       "            0.9966,     0.0110,     0.0000,     0.9654,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     1.0000,     0.0000,     0.0855,     0.0000,     0.9627,     0.0000,     0.9984,     1.0000,     0.0000,\n",
       "            0.0001,     0.0000,     0.0740,     0.0000,     0.9904,     0.0000,     0.0000,     0.0423,     0.0000,     1.0000,     0.9984,\n",
       "            0.0000,     1.0000,     0.0156,     0.0000,     0.0815,     1.0000,     0.0184,     0.0000,     1.0000,     0.0000,     0.0000,\n",
       "            0.9936,     1.0000,     0.0349,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0780,     0.0577,     0.0000,\n",
       "            0.9976,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.9958,     0.0000,     0.0000,     0.0000,     0.9981,\n",
       "            0.0000,     1.0000,     0.0000,     0.0000,     0.9983,     0.0000,     1.0000,     0.0000,     0.0066,     0.0238,     0.0000,\n",
       "            0.0054,     0.9923,     0.0769,     0.9923,     1.0000,     0.0615,     0.0000,     1.0000,     0.0000,     0.0000,     0.0000],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = calc_preds(tst_indep, weights)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e99d88bb-3d0f-41cd-907e-f66e7041ca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2656)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds > 0.5).sum() / preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6758213e-409e-4945-8388-8476dbd9abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV submission time!\n",
    "# Found on stack overflow https://stackoverflow.com/questions/36158058/torch-save-tensor-to-csv-file\n",
    "preds_np = preds.detach().numpy() #convert to Numpy array\n",
    "preds_df = pd.DataFrame(t_np) #convert to a dataframe\n",
    "# df.to_csv(\"testfile\",index=False) #save to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0171f351-f835-4abf-8bbd-3d4b23ba092d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.660216e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.446008e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.016978e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.662470e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.488586e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>4.350830e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>9.999956e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2.569265e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>4.350830e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1.450977e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0    4.660216e-06\n",
       "1    2.446008e-02\n",
       "2    2.016978e-02\n",
       "3    3.662470e-09\n",
       "4    4.488586e-02\n",
       "..            ...\n",
       "413  4.350830e-09\n",
       "414  9.999956e-01\n",
       "415  2.569265e-09\n",
       "416  4.350830e-09\n",
       "417  1.450977e-06\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "856c6150-5c79-4932-95c5-fad707fd5af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/fastai_work/replication\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c9821fd-f361-40d0-a56a-b0259dd72c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name     Sex   Age  SibSp  Parch              Ticket      Fare Cabin  \\\n",
       "0            892       3                              Kelly, Mr. James    male  34.5      0      0              330911    7.8292   NaN   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0              363272    7.0000   NaN   \n",
       "2            894       2                     Myles, Mr. Thomas Francis    male  62.0      0      0              240276    9.6875   NaN   \n",
       "3            895       3                              Wirz, Mr. Albert    male  27.0      0      0              315154    8.6625   NaN   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1             3101298   12.2875   NaN   \n",
       "..           ...     ...                                           ...     ...   ...    ...    ...                 ...       ...   ...   \n",
       "413         1305       3                            Spector, Mr. Woolf    male   NaN      0      0           A.5. 3236    8.0500   NaN   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina  female  39.0      0      0            PC 17758  108.9000  C105   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN   \n",
       "416         1308       3                           Ware, Mr. Frederick    male   NaN      0      0              359309    8.0500   NaN   \n",
       "417         1309       3                      Peter, Master. Michael J    male   NaN      1      1                2668   22.3583   NaN   \n",
       "\n",
       "    Embarked  \n",
       "0          Q  \n",
       "1          S  \n",
       "2          Q  \n",
       "3          S  \n",
       "4          S  \n",
       "..       ...  \n",
       "413        S  \n",
       "414        C  \n",
       "415        S  \n",
       "416        S  \n",
       "417        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('titanic/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0229c2bb-385a-4a56-834c-5fa47649c2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>4.660216e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>2.446008e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2.016978e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3.662470e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>4.488586e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>4.350830e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>9.999956e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>2.569265e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>4.350830e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1.450977e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId      Survived\n",
       "0            892  4.660216e-06\n",
       "1            893  2.446008e-02\n",
       "2            894  2.016978e-02\n",
       "3            895  3.662470e-09\n",
       "4            896  4.488586e-02\n",
       "..           ...           ...\n",
       "413         1305  4.350830e-09\n",
       "414         1306  9.999956e-01\n",
       "415         1307  2.569265e-09\n",
       "416         1308  4.350830e-09\n",
       "417         1309  1.450977e-06\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df['PassengerId'] = test_df['PassengerId']\n",
    "preds_df.rename(columns={0: 'Survived'}, inplace=True)\n",
    "preds_df = preds_df[['PassengerId', 'Survived']]\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1652ab4-fe42-475a-9bd9-e31a3735c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df['Survived'] = preds_df['Survived'].apply(lambda pred: 1 if pred >= 0.5 else 0)\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "56fac3d8-1c91-4407-ab07-45949150a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv(path/'submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f1790-eb7c-4dd5-bc86-4e01b2f90721",
   "metadata": {},
   "source": [
    "## Trying to build DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d20e8861-129c-4773-9f92-31e2782b1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_indep = trn_indep.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "007feea3-241d-4e70-a928-4a340371b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0c6831a2-e3b6-4455-9252-69226f6d9371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([713])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 713x13 @ 13x1 = 713x1\n",
    "(trn_indep@weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "40386e53-c121-4e3a-bd46-8233687576e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3532, -0.2323,  0.4296],\n",
       "        [-0.0981, -0.1847,  0.2546],\n",
       "        [-0.0486, -0.3390,  0.0537],\n",
       "        [-0.2328, -0.3618, -0.3155],\n",
       "        [ 0.1735,  0.0421, -0.2026],\n",
       "        [ 0.1785, -0.1565, -0.3859],\n",
       "        [ 0.1717, -0.1703, -0.1482],\n",
       "        [ 0.3594,  0.3737, -0.4894],\n",
       "        [ 0.4288,  0.4471, -0.3606],\n",
       "        [-0.4985, -0.3903, -0.1327],\n",
       "        [-0.0225,  0.1378,  0.1193],\n",
       "        [ 0.0969, -0.3903,  0.4812],\n",
       "        [ 0.4307,  0.2436,  0.1092]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So for 3 layers...\n",
    "weights_3 = torch.rand(trn_indep.shape[1], 3) - 0.5\n",
    "print(weights_3.shape)\n",
    "weights_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1dd2bb6b-cae3-4bca-bf1e-34a759e2a4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_84/3909039809.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??calc_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "72b31a3d-00bd-4b93-85c7-ffd7352151c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([713, 13]),\n",
       " tensor([[ 0.0282,  0.3899,  0.4677, -0.2318, -0.0000, -0.0000,  6.0422, -0.0000,  8.5909, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 1.1405,  0.0000,  0.0000, -0.1569, -0.0000, -0.0000,  6.0422, -0.0000,  8.5909, -0.0000, -2.8353,  0.0000, -0.3862],\n",
       "         [ 0.7603,  0.0000,  0.0000, -0.1655, -0.0000, -0.0000,  6.0422, -0.0000,  8.5909, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 0.8448,  0.3899,  0.0000, -0.2130, -0.0000, -0.0000,  6.0422, -0.0000,  8.5909, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 0.0845,  1.1696,  0.2339, -0.2336, -0.0000, -0.0000,  6.0422, -8.1473,  0.0000, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 0.9574,  0.0000,  0.2339, -0.2403, -0.0000, -3.1499,  0.0000, -8.1473,  0.0000, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 0.8729,  0.3899,  0.0000, -0.3625, -2.8693, -0.0000,  0.0000, -8.1473,  0.0000, -1.7337, -0.0000,  0.0000, -0.3862],\n",
       "         ...,\n",
       "         [ 0.5069,  0.0000,  0.0000, -0.1572, -0.0000, -0.0000,  6.0422, -8.1473,  0.0000, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 1.0137,  0.0000,  0.0000,  1.7646, -0.0000, -0.0000,  6.0422, -0.0000,  8.5909, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 0.5913,  0.0000,  0.0000, -0.1586, -0.0000, -0.0000,  6.0422, -0.0000,  8.5909, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 1.3235,  0.0000,  0.0000, -0.2798, -2.8693, -0.0000,  0.0000, -0.0000,  8.5909, -0.0000, -0.0000,  4.5434, -0.3862],\n",
       "         [ 0.6758,  0.0000,  0.0000, -0.1582, -0.0000, -0.0000,  6.0422, -8.1473,  0.0000, -0.0000, -2.8353,  0.0000, -0.3862],\n",
       "         [ 0.4787,  0.3899,  0.2339, -0.1516, -0.0000, -0.0000,  6.0422, -0.0000,  8.5909, -1.7337, -0.0000,  0.0000, -0.3862],\n",
       "         [ 1.0137,  0.0000,  0.0000, -0.1966, -0.0000, -3.1499,  0.0000, -0.0000,  8.5909, -0.0000, -0.0000,  4.5434, -0.3862]],\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trn_indep*weights).shape, trn_indep*weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0f622fc1-b494-48ac-87aa-59e16f035dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([713]),\n",
       " tensor([ 19.4443,  12.3950,  19.3851,  19.8119,   3.3064,  -6.1890, -12.2362,  19.4204,  19.4208,  10.3775,  10.6138,  10.4036,  19.3077,\n",
       "          20.4986,  -6.3228,  -4.8078,  -6.3628,   2.5681,  11.3683,  10.5714,  10.8406, -11.5391,  19.3203,  19.3143,  19.5334,  19.8694,\n",
       "           2.5411,  19.5624,  10.6399,  -5.0014,  19.1373,   2.9611,  -5.9265,  -6.1252,  19.3112,   3.9425,  19.1948,  10.0207,  21.0899,\n",
       "           4.0890,  -6.3963,  -6.3564,   2.4498,   3.4472,  -6.2945,  -6.4530,  19.5436,  20.4532,   4.3878,  19.9619,  20.1117,  12.3192,\n",
       "           2.6537,  19.1832,  19.4752,  19.5541,  10.6420,  19.0810,  19.3077,  -6.0338,   9.9179,  19.2385,  -4.4710,   3.8616,  10.4998,\n",
       "           3.5403,  -6.1689,  -5.0331,  10.3937,   2.6256,  -4.8090, -11.7620,  10.7533,  19.3063,   4.4421,  10.8444, -12.5549,   4.4735,\n",
       "          10.9792,   3.3437,  10.9182,  10.7122,   2.5727,  -6.5036,  -3.5567, -12.5574,  11.2590,  10.6847,  19.3383,  11.2149,  21.9347,\n",
       "           4.4194,  10.2464,  13.0205,   4.1091,  -5.9099,  -4.8078,   4.0229,   2.5681,  19.0810,   2.3955,   2.7281,  19.3077,   4.1653,\n",
       "          19.3063,  -3.6316,  13.0374,  19.9454,  10.1056,  12.9843,  19.3164,  11.3175,  10.8096,  -5.4493,  -5.2158,  19.3077, -12.7855,\n",
       "          20.1367,  19.1035,  -5.7868,  11.9304,   2.9799,   4.5410,  19.1569,  -5.1191,  13.0374,   3.8832,   5.0106,  19.1809,  12.0386,\n",
       "          19.5327,  10.3526,  10.2518,  10.9166,  19.3446,  19.5612,  -3.7008,  10.1872,  -6.6134,   9.8685,  19.5060, -12.4824,  19.4344,\n",
       "           5.3497,  -4.9498,  -6.1071,  12.2672,  11.1485,  -5.7291,   3.8449,  10.1901,   4.1873,  10.6395,  20.7169,  10.2548,   3.9391,\n",
       "          19.6265,  19.1569,  19.7943,  -6.5460,  13.0027,  13.0555,  -4.8078,  19.3652,  20.0437, -12.6015,  19.4017,  13.0306,  11.4313,\n",
       "          22.7276,  13.4888, -11.9858,   4.6176,   3.2368,  12.3192,  19.3822,  11.2408,  -5.8447,  19.7568,  10.4423,  11.9304,   5.3293,\n",
       "          10.1710, -12.6291,   2.8190,  -4.0106,  12.7698,  -4.5050,  12.5947,  10.3341,  19.1694,   4.9750, -12.4087,  11.1639,  19.7020,\n",
       "          19.3641,  20.1935,   2.4964,  10.6417, -12.8215,  -4.9733,  -5.3549,  19.1669,  19.2157,  19.3063,  -6.7256,  -4.6247,  11.2765,\n",
       "          10.0567,   4.0151,  11.1967, -11.8090,  13.2770,  10.3922,  19.1475,  19.3077,  -5.6826,   2.5730,  10.3033,  11.9237,  19.6430,\n",
       "          19.3087,  20.0502,  20.6957,  10.1216,  -4.8078,  11.6913,  10.4993,   3.9844,  19.6160,   2.9048,   2.7314,  20.1933,  19.3641,\n",
       "          11.1824,   3.2599,  -6.2568,   3.5706,  10.5849,  13.0233,  11.1477,  19.1398,   3.2819,  20.6214,  10.9538,  12.0386,  10.0818,\n",
       "          -5.0639,  19.3077,  -3.6890,   4.1251,  10.2628,   4.3360,  -3.2973, -12.4684,  19.3400,  19.7269,   2.4046,  -6.4355,  10.8724,\n",
       "          20.0666, -12.9705,  19.4832,  19.6262,  -3.4170,  19.6340,   2.5144,  19.8075,  11.9304,  12.9811,  11.8461,   4.4172,  10.9033,\n",
       "          19.5315,  -3.6264,  19.5470,   2.5574,  12.9811, -11.6645,  -5.4729,  10.6793,  20.9869,  19.1655,  -3.7008,  -5.0329,   3.6529,\n",
       "           3.3125,  -5.8937,   2.4913,   3.7954,  19.5046,  19.7543,  10.2675,  20.3296, -12.2257,   9.8313,  -6.6439,  22.7276,  10.3590,\n",
       "           2.9060,  13.0591,  12.9247,  -5.7884,  11.9304,  20.0384,  -5.6078,  -5.9122,  13.2841,  -6.3791,  19.4497,  11.9307,  13.3419,\n",
       "         -12.7607,   4.9051,  -5.4774,   3.5605,  19.2612,  19.3424,  19.8695, -11.6769,   9.8602,  10.1619,  12.0386,   2.5608,  10.3049,\n",
       "          19.2865,  18.9997,  -6.2719,  19.4752,   4.3993,  11.0723,   2.9207, -13.1288,  -3.9404,  10.2065,  -5.8171,  -3.6175,   9.9530,\n",
       "          -6.6607,  -6.2501,  11.3734,  10.3720,  11.3892,   2.2884,  19.8583,   4.3895,  -6.6395,  20.4541,  11.8773,  -4.8066,  -6.3240,\n",
       "          19.2162,  19.3077,  10.6958,  11.3302,  13.1435,  13.4077,  19.1955,   4.0229,  -5.3673,  10.9477,  19.2499,  13.3404, -12.3483,\n",
       "          19.2799,  20.1670,  -5.7151,  -6.7321,  19.2580,  -6.4648,   3.7891,  13.6039,  19.2524,  19.3626,  -5.8230,   2.9048,  12.0712,\n",
       "           3.6319,  19.3077,  19.3154,   2.1623,  19.4214,  19.4062, -11.6995,  13.0374,  -4.8076,  20.0018,   4.4457, -12.3576,  19.3006,\n",
       "         -12.7632,  10.4998,  -5.8037,  12.1275,   5.9894,  -5.8288,   4.5620,  10.4160,  -5.8256,   5.0418,  10.5843,  13.4305,  19.3164,\n",
       "           2.6215,   3.4440,  11.9304,  13.0374,  19.3077,  -3.9510,  13.4880,   1.9995, -12.3697,  -5.7032,  19.3089,  13.0374,  -5.3597,\n",
       "           2.7671,  19.3822,  13.0374,  -6.2249,  10.2822,  -6.6247,  19.6254,  10.0493, -12.4615,   4.2409,  20.0695,  11.9587,  19.0706,\n",
       "          -6.2114,  19.8180,  12.0386,  19.8413,  19.1035,  -6.2014,  -4.8115,   5.3402,  -4.8086,  13.4586,  11.6313,  -6.2232,  -6.3007,\n",
       "          19.2182, -12.6274,  19.2677,  19.5327,  -5.6797,   3.3960,   4.4649,  -6.2665,  10.0775,  -6.5599,  10.1407,  10.1056,  11.9304,\n",
       "           4.9162,  13.2398,  11.3001,  -6.7096,  -4.8081,  -6.1832,  10.3772,   4.3712,  20.6662,  -5.9792,  19.9840, -12.4149,  11.0061,\n",
       "          13.1641,  -6.0963, -11.8855,  -5.3780,  19.3077,  19.2580,  10.4807,  12.1470,  19.3063,   4.0176,   5.0273,  19.7583,  19.2514,\n",
       "          11.6307,  -3.0743,  -4.8893,  19.1400,  19.1185,  19.1782,  19.4487,  -4.9661,  -4.4710,  -6.6019,  10.2746,  19.3063,   5.3020,\n",
       "          12.3203,  -6.3624,   4.3122,  19.8976,  -7.0051,  -6.1548,  -4.8077, -11.5602,  19.3077,  10.0938,  19.1569,  13.1714,  21.1839,\n",
       "          19.6496,  -6.6974,  10.9497,  13.6429,  10.7245,  -4.8923,  11.0812,  19.2514,  20.6378,  20.5217,  19.3117,  -6.1188,  -5.7478,\n",
       "          -5.3590,  19.2696,  12.5981,   4.0688,  19.2414,  19.3077,  13.0306,  20.0612,  -4.4710,  19.3359,  10.8947,  13.2064,  10.7970,\n",
       "          -6.0965,   3.3172,  19.5847,  10.7244,  13.0374,  19.3089,   2.3837,  19.5878,  19.1350,  21.2589,  11.2487,  -6.6607,  19.2593,\n",
       "          20.0767,   4.9562,  19.8694,  12.2672,  20.1998, -12.4990,  10.3033,  19.1681, -11.9748,  19.2218,  -3.3641, -12.8939,  19.4062,\n",
       "           3.8832,  20.1483,  -5.2075,  10.3590,  10.1619,  19.3063,  19.3136,  11.6241,  -3.1494,  -6.4620,  19.2800,  -6.1832,  -6.3228,\n",
       "           4.7611,  19.3143,  13.7329,   4.3325,  -4.8078,  19.6478, -11.7534, -12.1521,  19.2298,  20.2999,  11.0968,  19.6635,  10.7803,\n",
       "           2.7034,   2.6822,   5.9894,  19.4471, -12.7995,  10.7635,  13.0374,   2.8582,  19.1402,  19.3057,  22.7276,   3.6877,   9.7991,\n",
       "          19.2237,  12.0386,  19.7298,   2.5448,  10.0286,  19.1687,  -6.5850,  19.3077,  -3.3641,  19.2551,   2.8528,  19.2499,  10.8659,\n",
       "           4.0732,  10.8388,  -5.7572,  -6.3131,  10.1088,  19.3063,   3.7610,  12.9699,  -6.2102,  11.9296,  11.9306,  10.0493,  11.8433,\n",
       "          19.2580,  20.0164,  19.3922,  10.4317,  10.0657,  19.7269,  19.7298,  -6.8415,   9.9085,   3.6198,  19.1880,  20.0819,   4.0294,\n",
       "          11.9398, -12.6557,  19.1644,  13.0231,  -6.5481,  19.1955,  12.0386,  -3.9542,  11.9306,  10.3353,  10.8691,  -4.7682,  -5.4995,\n",
       "           2.5147,  11.3171,  19.6160,   3.9956,  11.0636,  19.6905,  19.4204,  21.3066,   3.4308,  10.4512,  10.2811,  19.2242,   2.1500,\n",
       "          -6.4918,  -4.0119,  10.2346,  10.8995,  20.3677,  11.9304,  21.2221,  -6.3303,   5.9894,  19.2244,  20.2851,  -4.8078,  12.7135,\n",
       "           2.4875,  10.2915,  -6.8547,   5.2444,  12.7416,  10.0359,   3.2766,  20.3578,  13.0656,  19.7107, -12.7957,  10.2464,  -6.7677,\n",
       "          10.8630,   3.1623,  13.0374,  -3.3175,   5.0616,  10.8110,  -6.2203,  19.1669,  20.1837,  19.5878,  19.6456,   3.0954,  11.3274,\n",
       "           9.9179,  13.0850,  19.3932,  19.2242,   2.4018,  21.5686,  19.2230,  10.9225,  -4.8090,  13.4640,  10.4154],\n",
       "        grad_fn=<MvBackward0>))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trn_indep@weights).shape, trn_indep@weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f59f88f3-937d-43cd-b173-9d84b6fafa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3532, -0.2323,  0.4296],\n",
       "        [-0.0981, -0.1847,  0.2546],\n",
       "        [-0.0486, -0.3390,  0.0537],\n",
       "        [-0.2328, -0.3618, -0.3155],\n",
       "        [ 0.1735,  0.0421, -0.2026],\n",
       "        [ 0.1785, -0.1565, -0.3859],\n",
       "        [ 0.1717, -0.1703, -0.1482],\n",
       "        [ 0.3594,  0.3737, -0.4894],\n",
       "        [ 0.4288,  0.4471, -0.3606],\n",
       "        [-0.4985, -0.3903, -0.1327],\n",
       "        [-0.0225,  0.1378,  0.1193],\n",
       "        [ 0.0969, -0.3903,  0.4812],\n",
       "        [ 0.4307,  0.2436,  0.1092]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "66330ec3-5b2c-4875-9fe4-e678e27af88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2208],\n",
       "        [0.5365],\n",
       "        [0.1432]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_1 = torch.rand(weights_3.shape[1], 1)\n",
    "weights_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "15da3727-bc40-4c86-ac65-a8aa700cfd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9912, -0.1842, -0.0161],\n",
       "        [ 1.1112,  0.4219, -0.1663],\n",
       "        [ 1.1667, -0.0735,  0.1176],\n",
       "        [ 1.1446, -0.1412,  0.1341],\n",
       "        [ 0.9133, -0.2545, -0.0807],\n",
       "        [ 1.0904, -0.2666, -0.2519],\n",
       "        [ 0.4132, -0.1183, -0.7565],\n",
       "        ...,\n",
       "        [ 1.0616, -0.1145, -0.0542],\n",
       "        [ 2.1463,  1.3610,  1.4394],\n",
       "        [ 1.1436, -0.0509,  0.0898],\n",
       "        [ 1.2012, -0.0057,  0.0950],\n",
       "        [ 0.9683,  0.3955, -0.3846],\n",
       "        [ 0.5136, -0.1135, -0.5002],\n",
       "        [ 1.1981, -0.1094, -0.0924]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 713x13@13x3 = 713x3 = Nxn_dim\n",
    "trn_indep@weights_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "297ac092-4b26-4b57-a076-6d18ad235d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([713, 1]),\n",
       " tensor([[ 0.1177],\n",
       "         [ 0.4479],\n",
       "         [ 0.2350],\n",
       "         [ 0.1962],\n",
       "         [ 0.0535],\n",
       "         [ 0.0617],\n",
       "         [-0.0806],\n",
       "         [ 0.2395],\n",
       "         [ 0.2398],\n",
       "         [ 0.1312]]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_no_activ = trn_indep@weights_3@weights_1\n",
    "preds_no_activ.shape, preds_no_activ[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ec38f7c7-a5d5-4f05-8f2e-85983fa830c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_84/3909039809.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??calc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5c847f84-37de-4041-bb85-768236a413b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcalc_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_84/3909039809.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??calc_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1e3bc969-e10a-4a36-98b9-698adc579393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"relu(input, inplace=False) -> Tensor\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Applies the rectified linear unit function element-wise. See\u001b[0m\n",
       "\u001b[0;34m    :class:`~torch.nn.ReLU` for more details.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b035af5c-c683-400c-9710-c2489515138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def relu(x):\n",
    "    return math.max(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "73df6264-58d6-4833-91df-897e15151e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3260],\n",
       "        [0.3130],\n",
       "        [0.3308],\n",
       "        [0.3258],\n",
       "        [0.3124],\n",
       "        [0.3158],\n",
       "        [0.2991],\n",
       "        [0.3309],\n",
       "        [0.3309],\n",
       "        [0.3106],\n",
       "        [0.3152],\n",
       "        [0.3300],\n",
       "        [0.3314],\n",
       "        [0.3171],\n",
       "        [0.3178],\n",
       "        [0.3064],\n",
       "        [0.3186],\n",
       "        [0.3206],\n",
       "        [0.3103],\n",
       "        [0.3258],\n",
       "        [0.3280],\n",
       "        [0.2985],\n",
       "        [0.3313],\n",
       "        [0.3316],\n",
       "        [0.3305],\n",
       "        [0.3291],\n",
       "        [0.3207],\n",
       "        [0.3304],\n",
       "        [0.3208],\n",
       "        [0.2991],\n",
       "        [0.3320],\n",
       "        [0.3161],\n",
       "        [0.3113],\n",
       "        [0.3054],\n",
       "        [0.3315],\n",
       "        [0.3066],\n",
       "        [0.3318],\n",
       "        [0.3278],\n",
       "        [0.4266],\n",
       "        [0.3043],\n",
       "        [0.3148],\n",
       "        [0.3059],\n",
       "        [0.3208],\n",
       "        [0.3119],\n",
       "        [0.3127],\n",
       "        [0.3045],\n",
       "        [0.3295],\n",
       "        [0.3241],\n",
       "        [0.3054],\n",
       "        [0.3291],\n",
       "        [0.3238],\n",
       "        [0.4135],\n",
       "        [0.3203],\n",
       "        [0.3314],\n",
       "        [0.3306],\n",
       "        [0.3301],\n",
       "        [0.3151],\n",
       "        [0.3322],\n",
       "        [0.3314],\n",
       "        [0.3139],\n",
       "        [0.3315],\n",
       "        [0.3311],\n",
       "        [0.3037],\n",
       "        [0.3051],\n",
       "        [0.3290],\n",
       "        [0.3180],\n",
       "        [0.3039],\n",
       "        [0.3070],\n",
       "        [0.3151],\n",
       "        [0.3204],\n",
       "        [0.3064],\n",
       "        [0.2978],\n",
       "        [0.3281],\n",
       "        [0.3313],\n",
       "        [0.3046],\n",
       "        [0.3241],\n",
       "        [0.3021],\n",
       "        [0.3071],\n",
       "        [0.3141],\n",
       "        [0.3136],\n",
       "        [0.3239],\n",
       "        [0.3253],\n",
       "        [0.3173],\n",
       "        [0.3191],\n",
       "        [0.3099],\n",
       "        [0.3001],\n",
       "        [0.3230],\n",
       "        [0.3192],\n",
       "        [0.3313],\n",
       "        [0.3226],\n",
       "        [0.4214],\n",
       "        [0.3037],\n",
       "        [0.3299],\n",
       "        [0.3190],\n",
       "        [0.3033],\n",
       "        [0.3034],\n",
       "        [0.3064],\n",
       "        [0.3082],\n",
       "        [0.3206],\n",
       "        [0.3322],\n",
       "        [0.3181],\n",
       "        [0.3167],\n",
       "        [0.3314],\n",
       "        [0.3063],\n",
       "        [0.3313],\n",
       "        [0.3104],\n",
       "        [0.3212],\n",
       "        [0.3285],\n",
       "        [0.3304],\n",
       "        [0.3197],\n",
       "        [0.3317],\n",
       "        [0.3106],\n",
       "        [0.3279],\n",
       "        [0.3038],\n",
       "        [0.3032],\n",
       "        [0.3314],\n",
       "        [0.3014],\n",
       "        [0.3249],\n",
       "        [0.3319],\n",
       "        [0.3047],\n",
       "        [0.3143],\n",
       "        [0.3167],\n",
       "        [0.3142],\n",
       "        [0.3260],\n",
       "        [0.3020],\n",
       "        [0.3212],\n",
       "        [0.3101],\n",
       "        [0.3035],\n",
       "        [0.3313],\n",
       "        [0.4240],\n",
       "        [0.3305],\n",
       "        [0.3266],\n",
       "        [0.3146],\n",
       "        [0.3274],\n",
       "        [0.3316],\n",
       "        [0.3304],\n",
       "        [0.3128],\n",
       "        [0.3300],\n",
       "        [0.3048],\n",
       "        [0.3320],\n",
       "        [0.3306],\n",
       "        [0.2991],\n",
       "        [0.3303],\n",
       "        [0.3037],\n",
       "        [0.3068],\n",
       "        [0.3074],\n",
       "        [0.3109],\n",
       "        [0.3111],\n",
       "        [0.3066],\n",
       "        [0.3059],\n",
       "        [0.3301],\n",
       "        [0.3052],\n",
       "        [0.3249],\n",
       "        [0.3262],\n",
       "        [0.3147],\n",
       "        [0.3111],\n",
       "        [0.3258],\n",
       "        [0.3260],\n",
       "        [0.3298],\n",
       "        [0.3187],\n",
       "        [0.3054],\n",
       "        [0.3190],\n",
       "        [0.3064],\n",
       "        [0.3312],\n",
       "        [0.3281],\n",
       "        [0.3013],\n",
       "        [0.3314],\n",
       "        [0.3210],\n",
       "        [0.3129],\n",
       "        [0.3064],\n",
       "        [0.3166],\n",
       "        [0.3008],\n",
       "        [0.3064],\n",
       "        [0.3150],\n",
       "        [0.4135],\n",
       "        [0.3252],\n",
       "        [0.3107],\n",
       "        [0.3048],\n",
       "        [0.3260],\n",
       "        [0.3256],\n",
       "        [0.3143],\n",
       "        [0.3048],\n",
       "        [0.3253],\n",
       "        [0.2983],\n",
       "        [0.3186],\n",
       "        [0.3139],\n",
       "        [0.4104],\n",
       "        [0.3030],\n",
       "        [0.3222],\n",
       "        [0.3275],\n",
       "        [0.3320],\n",
       "        [0.3058],\n",
       "        [0.2999],\n",
       "        [0.3274],\n",
       "        [0.3298],\n",
       "        [0.3311],\n",
       "        [0.3258],\n",
       "        [0.3203],\n",
       "        [0.3151],\n",
       "        [0.3008],\n",
       "        [0.2990],\n",
       "        [0.3021],\n",
       "        [0.3319],\n",
       "        [0.3320],\n",
       "        [0.3313],\n",
       "        [0.3171],\n",
       "        [0.3059],\n",
       "        [0.3270],\n",
       "        [0.3267],\n",
       "        [0.3080],\n",
       "        [0.3100],\n",
       "        [0.2967],\n",
       "        [0.3199],\n",
       "        [0.3282],\n",
       "        [0.3312],\n",
       "        [0.3314],\n",
       "        [0.3024],\n",
       "        [0.3207],\n",
       "        [0.3161],\n",
       "        [0.3141],\n",
       "        [0.3264],\n",
       "        [0.3314],\n",
       "        [0.3262],\n",
       "        [0.3165],\n",
       "        [0.3137],\n",
       "        [0.3064],\n",
       "        [0.3070],\n",
       "        [0.3128],\n",
       "        [0.3085],\n",
       "        [0.3301],\n",
       "        [0.3163],\n",
       "        [0.3197],\n",
       "        [0.3279],\n",
       "        [0.3311],\n",
       "        [0.3230],\n",
       "        [0.3152],\n",
       "        [0.3064],\n",
       "        [0.3139],\n",
       "        [0.3152],\n",
       "        [0.3212],\n",
       "        [0.3110],\n",
       "        [0.3321],\n",
       "        [0.3120],\n",
       "        [0.3190],\n",
       "        [0.3143],\n",
       "        [0.4240],\n",
       "        [0.3276],\n",
       "        [0.3070],\n",
       "        [0.3314],\n",
       "        [0.3111],\n",
       "        [0.3081],\n",
       "        [0.3305],\n",
       "        [0.3075],\n",
       "        [0.3081],\n",
       "        [0.3086],\n",
       "        [0.3280],\n",
       "        [0.3282],\n",
       "        [0.3214],\n",
       "        [0.3182],\n",
       "        [0.3137],\n",
       "        [0.3284],\n",
       "        [0.3109],\n",
       "        [0.3309],\n",
       "        [0.3305],\n",
       "        [0.3084],\n",
       "        [0.3255],\n",
       "        [0.3209],\n",
       "        [0.3291],\n",
       "        [0.3143],\n",
       "        [0.3214],\n",
       "        [0.3145],\n",
       "        [0.3094],\n",
       "        [0.3142],\n",
       "        [0.3304],\n",
       "        [0.3109],\n",
       "        [0.3298],\n",
       "        [0.3173],\n",
       "        [0.3214],\n",
       "        [0.2986],\n",
       "        [0.3031],\n",
       "        [0.3103],\n",
       "        [0.3196],\n",
       "        [0.3319],\n",
       "        [0.3128],\n",
       "        [0.3070],\n",
       "        [0.3161],\n",
       "        [0.3159],\n",
       "        [0.3134],\n",
       "        [0.3201],\n",
       "        [0.3199],\n",
       "        [0.3306],\n",
       "        [0.3281],\n",
       "        [0.3151],\n",
       "        [0.3176],\n",
       "        [0.3057],\n",
       "        [0.3286],\n",
       "        [0.3162],\n",
       "        [0.3064],\n",
       "        [0.3295],\n",
       "        [0.3164],\n",
       "        [0.3053],\n",
       "        [0.3216],\n",
       "        [0.3046],\n",
       "        [0.3143],\n",
       "        [0.3285],\n",
       "        [0.3123],\n",
       "        [0.3170],\n",
       "        [0.3201],\n",
       "        [0.3180],\n",
       "        [0.3308],\n",
       "        [0.3143],\n",
       "        [0.3204],\n",
       "        [0.3071],\n",
       "        [0.3056],\n",
       "        [0.3059],\n",
       "        [0.3143],\n",
       "        [0.3296],\n",
       "        [0.3315],\n",
       "        [0.3256],\n",
       "        [0.2993],\n",
       "        [0.3261],\n",
       "        [0.3302],\n",
       "        [0.4240],\n",
       "        [0.3203],\n",
       "        [0.3162],\n",
       "        [0.3276],\n",
       "        [0.3309],\n",
       "        [0.3057],\n",
       "        [0.3306],\n",
       "        [0.3101],\n",
       "        [0.3241],\n",
       "        [0.3187],\n",
       "        [0.3117],\n",
       "        [0.3116],\n",
       "        [0.3307],\n",
       "        [0.3134],\n",
       "        [0.3104],\n",
       "        [0.3317],\n",
       "        [0.3190],\n",
       "        [0.3048],\n",
       "        [0.3130],\n",
       "        [0.3145],\n",
       "        [0.3267],\n",
       "        [0.3218],\n",
       "        [0.3298],\n",
       "        [0.3098],\n",
       "        [0.3173],\n",
       "        [0.3191],\n",
       "        [0.3129],\n",
       "        [0.3064],\n",
       "        [0.3149],\n",
       "        [0.3314],\n",
       "        [0.3314],\n",
       "        [0.3248],\n",
       "        [0.3127],\n",
       "        [0.3051],\n",
       "        [0.3186],\n",
       "        [0.3318],\n",
       "        [0.3082],\n",
       "        [0.3030],\n",
       "        [0.3107],\n",
       "        [0.3315],\n",
       "        [0.3199],\n",
       "        [0.3007],\n",
       "        [0.3281],\n",
       "        [0.3246],\n",
       "        [0.3164],\n",
       "        [0.3168],\n",
       "        [0.3318],\n",
       "        [0.3154],\n",
       "        [0.3197],\n",
       "        [0.3163],\n",
       "        [0.3316],\n",
       "        [0.3311],\n",
       "        [0.3039],\n",
       "        [0.3163],\n",
       "        [0.3139],\n",
       "        [0.3118],\n",
       "        [0.3314],\n",
       "        [0.3317],\n",
       "        [0.3213],\n",
       "        [0.3309],\n",
       "        [0.3304],\n",
       "        [0.2985],\n",
       "        [0.3212],\n",
       "        [0.3064],\n",
       "        [0.3226],\n",
       "        [0.3093],\n",
       "        [0.2995],\n",
       "        [0.3311],\n",
       "        [0.3015],\n",
       "        [0.3290],\n",
       "        [0.3156],\n",
       "        [0.3137],\n",
       "        [0.3000],\n",
       "        [0.3038],\n",
       "        [0.3051],\n",
       "        [0.3158],\n",
       "        [0.3127],\n",
       "        [0.3030],\n",
       "        [0.3287],\n",
       "        [0.3172],\n",
       "        [0.3317],\n",
       "        [0.3198],\n",
       "        [0.3146],\n",
       "        [0.3143],\n",
       "        [0.3212],\n",
       "        [0.3314],\n",
       "        [0.3122],\n",
       "        [0.3196],\n",
       "        [0.3216],\n",
       "        [0.2988],\n",
       "        [0.3118],\n",
       "        [0.3314],\n",
       "        [0.3212],\n",
       "        [0.3016],\n",
       "        [0.3199],\n",
       "        [0.3252],\n",
       "        [0.3212],\n",
       "        [0.3170],\n",
       "        [0.3155],\n",
       "        [0.3055],\n",
       "        [0.3304],\n",
       "        [0.3306],\n",
       "        [0.2996],\n",
       "        [0.3075],\n",
       "        [0.3285],\n",
       "        [0.3142],\n",
       "        [0.3318],\n",
       "        [0.3146],\n",
       "        [0.3295],\n",
       "        [0.4240],\n",
       "        [0.3292],\n",
       "        [0.3319],\n",
       "        [0.3169],\n",
       "        [0.3063],\n",
       "        [0.3027],\n",
       "        [0.3064],\n",
       "        [0.3171],\n",
       "        [0.3089],\n",
       "        [0.3151],\n",
       "        [0.3059],\n",
       "        [0.3315],\n",
       "        [0.3000],\n",
       "        [0.3310],\n",
       "        [0.3305],\n",
       "        [0.3043],\n",
       "        [0.3160],\n",
       "        [0.3069],\n",
       "        [0.3177],\n",
       "        [0.3305],\n",
       "        [0.3193],\n",
       "        [0.3117],\n",
       "        [0.3304],\n",
       "        [0.3143],\n",
       "        [0.3058],\n",
       "        [0.3110],\n",
       "        [0.3108],\n",
       "        [0.3161],\n",
       "        [0.3064],\n",
       "        [0.3145],\n",
       "        [0.3155],\n",
       "        [0.3027],\n",
       "        [0.3170],\n",
       "        [0.3155],\n",
       "        [0.3288],\n",
       "        [0.2998],\n",
       "        [0.3114],\n",
       "        [0.3208],\n",
       "        [0.3055],\n",
       "        [0.2984],\n",
       "        [0.3024],\n",
       "        [0.3314],\n",
       "        [0.3295],\n",
       "        [0.3243],\n",
       "        [0.3079],\n",
       "        [0.3313],\n",
       "        [0.3081],\n",
       "        [0.3033],\n",
       "        [0.3296],\n",
       "        [0.3316],\n",
       "        [0.3207],\n",
       "        [0.3083],\n",
       "        [0.3019],\n",
       "        [0.3321],\n",
       "        [0.3325],\n",
       "        [0.3312],\n",
       "        [0.3308],\n",
       "        [0.3071],\n",
       "        [0.3037],\n",
       "        [0.3068],\n",
       "        [0.3298],\n",
       "        [0.3313],\n",
       "        [0.3043],\n",
       "        [0.3122],\n",
       "        [0.3058],\n",
       "        [0.3160],\n",
       "        [0.3290],\n",
       "        [0.3176],\n",
       "        [0.3140],\n",
       "        [0.3064],\n",
       "        [0.2982],\n",
       "        [0.3314],\n",
       "        [0.3311],\n",
       "        [0.3260],\n",
       "        [0.3205],\n",
       "        [0.3186],\n",
       "        [0.3302],\n",
       "        [0.3170],\n",
       "        [0.3199],\n",
       "        [0.3191],\n",
       "        [0.3121],\n",
       "        [0.3066],\n",
       "        [0.3135],\n",
       "        [0.3316],\n",
       "        [0.3170],\n",
       "        [0.3223],\n",
       "        [0.3315],\n",
       "        [0.3042],\n",
       "        [0.3141],\n",
       "        [0.3105],\n",
       "        [0.3256],\n",
       "        [0.3204],\n",
       "        [0.3082],\n",
       "        [0.3312],\n",
       "        [0.3314],\n",
       "        [0.3210],\n",
       "        [0.3222],\n",
       "        [0.3037],\n",
       "        [0.3313],\n",
       "        [0.3143],\n",
       "        [0.3206],\n",
       "        [0.3106],\n",
       "        [0.3055],\n",
       "        [0.3142],\n",
       "        [0.3287],\n",
       "        [0.3205],\n",
       "        [0.3212],\n",
       "        [0.3314],\n",
       "        [0.3207],\n",
       "        [0.3302],\n",
       "        [0.3319],\n",
       "        [0.4256],\n",
       "        [0.3105],\n",
       "        [0.3190],\n",
       "        [0.3319],\n",
       "        [0.3287],\n",
       "        [0.3045],\n",
       "        [0.3291],\n",
       "        [0.3109],\n",
       "        [0.3250],\n",
       "        [0.2998],\n",
       "        [0.3161],\n",
       "        [0.3320],\n",
       "        [0.2997],\n",
       "        [0.3317],\n",
       "        [0.3096],\n",
       "        [0.3084],\n",
       "        [0.3304],\n",
       "        [0.3101],\n",
       "        [0.3235],\n",
       "        [0.3110],\n",
       "        [0.3295],\n",
       "        [0.3302],\n",
       "        [0.3313],\n",
       "        [0.3316],\n",
       "        [0.3049],\n",
       "        [0.3091],\n",
       "        [0.3064],\n",
       "        [0.3315],\n",
       "        [0.3145],\n",
       "        [0.3178],\n",
       "        [0.3076],\n",
       "        [0.3316],\n",
       "        [0.3144],\n",
       "        [0.3068],\n",
       "        [0.3064],\n",
       "        [0.3287],\n",
       "        [0.2984],\n",
       "        [0.3013],\n",
       "        [0.3320],\n",
       "        [0.3278],\n",
       "        [0.3123],\n",
       "        [0.3260],\n",
       "        [0.3245],\n",
       "        [0.3188],\n",
       "        [0.3202],\n",
       "        [0.3000],\n",
       "        [0.3307],\n",
       "        [0.3012],\n",
       "        [0.3116],\n",
       "        [0.3212],\n",
       "        [0.3178],\n",
       "        [0.3321],\n",
       "        [0.3313],\n",
       "        [0.3064],\n",
       "        [0.3104],\n",
       "        [0.3294],\n",
       "        [0.3317],\n",
       "        [0.4240],\n",
       "        [0.3297],\n",
       "        [0.3208],\n",
       "        [0.3268],\n",
       "        [0.3297],\n",
       "        [0.3087],\n",
       "        [0.3314],\n",
       "        [0.3096],\n",
       "        [0.3317],\n",
       "        [0.3181],\n",
       "        [0.3315],\n",
       "        [0.3278],\n",
       "        [0.3079],\n",
       "        [0.3119],\n",
       "        [0.3067],\n",
       "        [0.3066],\n",
       "        [0.3283],\n",
       "        [0.3313],\n",
       "        [0.3198],\n",
       "        [0.3230],\n",
       "        [0.3175],\n",
       "        [0.3143],\n",
       "        [0.3143],\n",
       "        [0.3306],\n",
       "        [0.3121],\n",
       "        [0.3318],\n",
       "        [0.3214],\n",
       "        [0.3310],\n",
       "        [0.3299],\n",
       "        [0.3312],\n",
       "        [0.3282],\n",
       "        [0.3297],\n",
       "        [0.3203],\n",
       "        [0.3312],\n",
       "        [0.3110],\n",
       "        [0.3316],\n",
       "        [0.3233],\n",
       "        [0.3064],\n",
       "        [0.3145],\n",
       "        [0.2991],\n",
       "        [0.3318],\n",
       "        [0.3208],\n",
       "        [0.3186],\n",
       "        [0.3318],\n",
       "        [0.4240],\n",
       "        [0.3137],\n",
       "        [0.3143],\n",
       "        [0.3298],\n",
       "        [0.3257],\n",
       "        [0.3104],\n",
       "        [0.3123],\n",
       "        [0.3209],\n",
       "        [0.3132],\n",
       "        [0.3301],\n",
       "        [0.3076],\n",
       "        [0.3139],\n",
       "        [0.3253],\n",
       "        [0.3309],\n",
       "        [0.3132],\n",
       "        [0.3138],\n",
       "        [0.3141],\n",
       "        [0.3155],\n",
       "        [0.3317],\n",
       "        [0.3209],\n",
       "        [0.3184],\n",
       "        [0.3025],\n",
       "        [0.3306],\n",
       "        [0.3128],\n",
       "        [0.3281],\n",
       "        [0.3143],\n",
       "        [0.3134],\n",
       "        [0.3040],\n",
       "        [0.3000],\n",
       "        [0.3318],\n",
       "        [0.3196],\n",
       "        [0.3064],\n",
       "        [0.4108],\n",
       "        [0.3210],\n",
       "        [0.3158],\n",
       "        [0.3178],\n",
       "        [0.3024],\n",
       "        [0.4106],\n",
       "        [0.3286],\n",
       "        [0.3139],\n",
       "        [0.3176],\n",
       "        [0.3211],\n",
       "        [0.3301],\n",
       "        [0.3012],\n",
       "        [0.3299],\n",
       "        [0.3182],\n",
       "        [0.3277],\n",
       "        [0.3184],\n",
       "        [0.3212],\n",
       "        [0.3005],\n",
       "        [0.3039],\n",
       "        [0.3146],\n",
       "        [0.3055],\n",
       "        [0.3319],\n",
       "        [0.3231],\n",
       "        [0.3302],\n",
       "        [0.3300],\n",
       "        [0.3174],\n",
       "        [0.3126],\n",
       "        [0.3315],\n",
       "        [0.3113],\n",
       "        [0.3311],\n",
       "        [0.3317],\n",
       "        [0.3213],\n",
       "        [0.4237],\n",
       "        [0.3317],\n",
       "        [0.3134],\n",
       "        [0.3064],\n",
       "        [0.3184],\n",
       "        [0.3293]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each layer gets its own matrix. Each matrix is its own transform like in graphics\n",
    "# old_dim x new_dim\n",
    "# prev.shape[1] x n_out\n",
    "\n",
    "# Need the last layer to give us one dimension prediction\n",
    "\n",
    "# TODO: Why relu -> sigmoid results in 0. But sigmoids all the way down results in 0.3?\n",
    "units_per_layer = [5,3,1]\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "layer_1 = torch.rand(trn_indep.shape[1], units_per_layer[0]).requires_grad_()\n",
    "layer_2 = torch.rand(units_per_layer[0], units_per_layer[1]).requires_grad_()\n",
    "layer_3 = torch.rand(units_per_layer[1], units_per_layer[2]).requires_grad_()\n",
    "\n",
    "layer_1_out = sigmoid(trn_indep@layer_1)\n",
    "layer_2_out = sigmoid(layer_1_out@layer_2)\n",
    "layer_3_out = sigmoid(layer_2_out@layer_3)\n",
    "layer_3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca03fe-3c3e-465d-9596-35460b28c873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61160f-edcd-465a-95e7-c98e07e8022e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2a4dd-37ee-466d-9cd1-24586cc25754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bfd3f9d8-d3be-44d2-8b00-2938bd8c2895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
      "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
      "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
      "        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194],\n",
      "        [0.5529, 0.9527, 0.0362, 0.1852, 0.3734],\n",
      "        [0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
      "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423],\n",
      "        [0.5263, 0.2437, 0.5846, 0.0332, 0.1387],\n",
      "        [0.2422, 0.8155, 0.7932, 0.2783, 0.4820],\n",
      "        [0.8198, 0.9971, 0.6984, 0.5675, 0.8352],\n",
      "        [0.2056, 0.5932, 0.1123, 0.1535, 0.2417],\n",
      "        [0.7262, 0.7011, 0.2038, 0.6511, 0.7745]], requires_grad=True) \n",
      "\n",
      "tensor([[0.4369, 0.5191, 0.6159],\n",
      "        [0.8102, 0.9801, 0.1147],\n",
      "        [0.3168, 0.6965, 0.9143],\n",
      "        [0.9351, 0.9412, 0.5995],\n",
      "        [0.0652, 0.5460, 0.1872]], requires_grad=True) \n",
      "\n",
      "tensor([[0.0340],\n",
      "        [0.9442],\n",
      "        [0.8802]], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(layer_1, '\\n')\n",
    "print(layer_2, '\\n')\n",
    "print(layer_3, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcda7d-c8c5-4c9d-abd2-0c772af8bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "global weights\n",
    "\n",
    "\n",
    "\n",
    "def training_step(step, lr):\n",
    "    global weights\n",
    "    \n",
    "    loss = calc_loss(trn_indep, weights, trn_dep)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        weights.sub_(weights.grad * lr)\n",
    "        weights.grad.zero_()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            trn_loss = calc_loss(trn_indep, weights, trn_dep).item()\n",
    "            val_loss = calc_loss(val_indep, weights, val_dep).item()\n",
    "            print(trn_loss, val_loss)\n",
    "        \n",
    "        \n",
    "def train(steps=10000, lr=0.1):\n",
    "    torch.manual_seed(0)\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    global weights\n",
    "    weights = torch.rand(train_df.shape[1]) - 0.5\n",
    "    weights.requires_grad_()\n",
    "    \n",
    "    for i in range(steps):\n",
    "        training_step(i, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
